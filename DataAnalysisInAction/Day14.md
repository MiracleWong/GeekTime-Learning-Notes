# 【第三期】21 天打卡行动

#21 天打卡# Day14
专栏：数据分析实战 45 讲
时间：2020-02-26
学习：24
学习要点和总结：

一、24 丨 KNN（上）：如何根据打斗和接吻次数来划分电影类型？

1. KNN 的计算过程：1. 计算待分类物体与其他物体之间的距离；2. 统计距离最近的 K 个邻居；3. 对于 K 个最近的邻居，它们属于哪个分类最多，待分类物体就属于哪一类。
2. K 值应该是个实践出来的结果，采用交叉验证的方法。交叉验证的思路就是，把样本集中的大部分样本作为训练集，剩余的小部分样本用于预测，来验证分类模型的准确性。所以在 KNN 算法中，我们一般会把 K 值选取在较小的范围内，同时在验证集上准确率最高的那一个最终确定作为 K 值。
3. K 值的种类：欧氏距离；曼哈顿距离；闵可夫斯基距离；切比雪夫距离；余弦距离。
4. 欧氏距离是我们最常用的距离公式，也叫做欧几里得距离
5. 曼哈顿距离在几何空间中用的比较多，等于两个点在坐标系上绝对轴距总和。
6. 闵可夫斯基距离不是一个距离，而是一组距离的定义。
7. 切比雪夫距离就是这两个点坐标数值差的绝对值的最大值，用数学表示就是：max(|x1-y1|,|x2-y2|)。
8. 参余弦距离实际上计算的是两个向量的夹角，是在方向上计算两者之间的差异，余弦距离可以用于衡量用户对内容兴趣的区分度。
9. 用 KNN 进行回归，通过 K 个邻居对新的点的属性进行值的预测。
10. KNN 的优点和缺点：a.优点：KNN 的理论简单直接，针对 KNN 中的搜索也有相应的 KD 树这个数据结构。KNN 的理论成熟，可以应用到线性和非线性的分类问题中，也可以用于回归分析。b.缺点：不过 KNN 需要计算测试点与样本点之间的距离，当数据量大的时候，计算量是非常庞大的，需要大量的存储空间和计算时间。另外如果样本分类不均衡，比如有些分类的样本非常少，那么该类别的分类准确率就会低很多。
11. 老师推荐的 Kaggle 题目：a. 信用卡欺诈交易分类预测：https://www.kaggle.com/mlg-ulb/creditcardfraud b. 比特币趋势分析：https://www.kaggle.com/mczielinski/bitcoin-historical-data c. 宇宙中的脉冲星预测：https://www.kaggle.com/pavanraj159/predicting-a-pulsar-star d. 西班牙高铁票价：https://www.kaggle.com/thegurus/spanish-high-speed-rail-system-ticket-pricing
