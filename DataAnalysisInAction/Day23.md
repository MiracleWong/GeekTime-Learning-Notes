# 【第三期】21 天打卡行动

#21 天打卡# Day23
专栏：数据分析实战 45 讲
时间：2020-03-06
学习：34
学习要点和总结：

一、[34 丨 AdaBoost（上）：如何使用 AdaBoost 提升分类器性能？](https://time.geekbang.org/column/article/83915)

1. 在数据挖掘中，分类算法可以说是核心算法，其中 AdaBoost 算法与随机森林算法一样都属于分类算法中的集成算法。
2. 集成算法通常有两种方式，分别是投票选举（bagging）和再学习（boosting）。
3. Boosting 的含义是提升，它的作用是每一次训练的时候都对上一次的训练进行改进提升，在训练的过程中这 K 个"专家"之间是有依赖性的，当引入第 K 个"专家"（第 K 个分类器）的时候，实际上是对前 K-1 个专家的优化。而 bagging 在做投票选举的时候可以并行计算，也就是 K 个"专家"在做判断的时候是相互独立的，不存在依赖性。
4. Boosting 算法的原理：Boosting 算法是集成算法中的一种，同时也是一类算法的总称。这类算法通过训练多个弱分类器，将它们组合成一个强分类器。
5. AdaBoost 的英文全称是 Adaptive Boosting，中文含义是自适应提升算法。它由 Freund 等人于 1995 年提出，是对 Boosting 算法的一种实现。
6. 问题：每个弱分类器在强分类器中的权重是如何计算的？回答：在一个由 K 个弱分类器中组成的强分类器中，如果弱分类器的分类效果好，那么权重应该比较大，如果弱分类器的分类效果一般，权重应该降低。
7. 问题：在每次迭代训练的过程中，如何得到最优弱分类器？回答：AdaBoost 算法是通过改变样本的数据分布来实现的。AdaBoost 会判断每次训练的样本是否正确分类，对于正确分类的样本，降低它的权重，对于被错误分类的样本，增加它的权重。
8. AdaBoost 算法是一个框架，你可以指定任意的分类器，通常我们可以采用 CART 分类器作为弱分类器。
